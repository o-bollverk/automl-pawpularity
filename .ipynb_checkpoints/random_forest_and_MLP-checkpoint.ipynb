{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "# hyperopt==0.2.5\n",
    "import hyperopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hpsklearn import HyperoptEstimator,any_regressor, random_forest_regression, any_classifier, any_preprocessing\n",
    "from hpsklearn import one_hot_encoder, pca, standard_scaler, min_max_scaler, normalizer, ts_lagselector, tfidf, rbm, colkmeans\n",
    "from sklearn.datasets import load_iris\n",
    "from hyperopt import tpe\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of data, split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \n",
       "0          0      1        0      0          0     0     0           63  \n",
       "1          0      0        0      0          0     0     0           42  \n",
       "2          0      0        0      1          1     0     0           28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \n",
       "0          1      1        0      0          1     0     1  \n",
       "1          0      1        1      0          0     0     0  \n",
       "2          1      1        1      0          1     1     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data_dir = \"data\"\n",
    "data_dir = \"/media/revilo/oliver-kool-2/\"\n",
    "val_df = pd.read_csv(f'{data_dir}/test.csv')\n",
    "train_df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "\n",
    "display(train_df.head(3))\n",
    "display(val_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/revilo/oliver-kool-2/automl-pawpularity\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               [0007de18844b0dbbb5e1f607da0606e0, 0009c66b943...\n",
       "Subject Focus                                               [0, 1]\n",
       "Eyes                                                        [1, 0]\n",
       "Face                                                        [1, 0]\n",
       "Near                                                        [1, 0]\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.apply(lambda x: x.unique()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test  test.csv  train  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "X = train_df.iloc[:, :(train_df.shape[1] -1)].drop(\"Id\", axis = 1)\n",
    "Y = train_df.iloc[:, train_df.shape[1] - 1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    random_state = 0,\n",
    "                                                   train_size= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.33trial/s, best loss: 0.9697732997481109]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.38trial/s, best loss: 0.9697732997481109]\n",
      " 67%|██████▋   | 2/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:33] WARNING: ../src/learner.cc:541:           \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:07:33] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 3/3 [00:41<00:00, 41.62s/trial, best loss: 0.9697732997481109]\n",
      " 75%|███████▌  | 3/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:08:15] WARNING: ../src/learner.cc:541:           \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[14:08:15] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 4/4 [00:07<00:00,  7.06s/trial, best loss: 0.9697732997481109]\n",
      "100%|██████████| 5/5 [01:06<00:00, 66.26s/trial, best loss: 0.9697732997481109]\n",
      "100%|██████████| 6/6 [00:32<00:00, 32.15s/trial, best loss: 0.9697732997481109]\n",
      "100%|██████████| 7/7 [00:00<00:00,  4.34trial/s, best loss: 0.9697732997481109]\n",
      "100%|██████████| 8/8 [00:00<00:00,  1.20trial/s, best loss: 0.9697732997481109]\n",
      "100%|██████████| 9/9 [00:00<00:00,  1.78trial/s, best loss: 0.9672544080604534]\n",
      "100%|██████████| 10/10 [00:00<00:00,  7.52trial/s, best loss: 0.9672544080604534]\n",
      "0.03114754098360656\n",
      "{'learner': RandomForestClassifier(bootstrap=False, max_depth=2, max_features='sqrt',\n",
      "                       min_samples_leaf=2, n_estimators=807, n_jobs=1,\n",
      "                       random_state=3, verbose=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "estim = HyperoptEstimator(classifier= any_classifier('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=10,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "estim.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Estimated score: {estim.score(X_test, Y_test)}')\n",
    "print(f'Estimated best model: {estim.best_model()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any preprocessing + random_forest_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.80trial/s, best loss: 1.0334200194809722]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.01trial/s, best loss: 1.0308326407773305]\n",
      "100%|██████████| 3/3 [00:00<00:00,  1.14trial/s, best loss: 1.0029970931383272]\n",
      "100%|██████████| 4/4 [00:00<00:00, 15.14trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 5/5 [00:00<00:00,  2.62trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 6/6 [00:00<00:00, 22.17trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 7/7 [00:00<00:00, 25.16trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 8/8 [00:00<00:00, 34.85trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 9/9 [00:00<00:00, 30.73trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15.72trial/s, best loss: 1.0022017109015546]\n",
      "100%|██████████| 11/11 [00:00<00:00,  1.09trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 12/12 [00:00<00:00, 31.89trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 13/13 [00:00<00:00,  1.88trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 14/14 [00:00<00:00,  2.26trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 15/15 [00:00<00:00,  1.85trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 16/16 [00:00<00:00, 10.71trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 17/17 [00:00<00:00, 27.77trial/s, best loss: 0.9997365058560916]\n",
      "100%|██████████| 18/18 [00:05<00:00,  5.83s/trial, best loss: 0.9997365058560916]\n",
      "100%|██████████| 19/19 [00:00<00:00,  5.88trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 20/20 [00:00<00:00, 26.94trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 21/21 [00:00<00:00,  6.58trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 22/22 [00:00<00:00, 34.49trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 23/23 [00:01<00:00,  1.22s/trial, best loss: 0.9983041595509391]\n",
      "100%|██████████| 24/24 [00:00<00:00,  5.36trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 25/25 [00:00<00:00,  1.44trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 26/26 [00:00<00:00,  4.77trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 27/27 [00:00<00:00,  4.84trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 28/28 [00:00<00:00,  4.74trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 29/29 [00:00<00:00,  5.86trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 30/30 [00:00<00:00,  5.00trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 31/31 [00:00<00:00,  1.97trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 32/32 [00:00<00:00,  4.81trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 33/33 [00:00<00:00,  4.77trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 34/34 [00:00<00:00, 14.15trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 35/35 [00:00<00:00,  3.83trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 36/36 [00:00<00:00,  3.64trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 37/37 [00:00<00:00,  1.41trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 38/38 [00:00<00:00, 30.16trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 39/39 [00:00<00:00,  2.55trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 40/40 [00:00<00:00,  1.16trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 41/41 [00:00<00:00,  9.11trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 42/42 [00:00<00:00, 13.77trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 43/43 [00:00<00:00,  1.23trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 44/44 [00:00<00:00, 19.22trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 45/45 [00:00<00:00,  6.84trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 46/46 [00:00<00:00,  3.06trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 47/47 [00:00<00:00,  9.55trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 48/48 [00:00<00:00,  1.72trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 49/49 [00:00<00:00, 15.48trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 50/50 [00:00<00:00,  3.44trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 51/51 [00:00<00:00,  8.38trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 52/52 [00:01<00:00,  1.22s/trial, best loss: 0.9983041595509391]\n",
      "100%|██████████| 53/53 [00:00<00:00,  1.90trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 54/54 [00:00<00:00,  9.44trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 55/55 [00:00<00:00,  8.22trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 56/56 [00:00<00:00,  4.50trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 57/57 [00:00<00:00, 15.63trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 58/58 [00:00<00:00,  6.63trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 59/59 [00:00<00:00, 13.08trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 60/60 [00:00<00:00,  1.91trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 61/61 [00:00<00:00, 21.23trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 62/62 [00:00<00:00,  3.95trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 63/63 [00:00<00:00,  1.19trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 64/64 [00:00<00:00,  1.27trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 65/65 [00:00<00:00,  9.82trial/s, best loss: 0.9983041595509391]\n",
      "100%|██████████| 66/66 [00:00<00:00,  4.10trial/s, best loss: 0.9981931814190383]\n",
      "100%|██████████| 67/67 [00:00<00:00,  3.98trial/s, best loss: 0.9981931814190383]\n",
      "100%|██████████| 68/68 [00:00<00:00,  2.69trial/s, best loss: 0.9981931814190383]\n",
      "100%|██████████| 69/69 [00:00<00:00,  4.20trial/s, best loss: 0.9981931814190383]\n",
      "100%|██████████| 70/70 [00:00<00:00, 10.29trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 71/71 [00:00<00:00, 16.22trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 72/72 [00:00<00:00,  5.02trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 73/73 [00:00<00:00,  1.76trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 74/74 [00:00<00:00, 11.09trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 75/75 [00:00<00:00, 12.64trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 76/76 [00:00<00:00,  5.82trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 77/77 [00:00<00:00, 20.04trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 78/78 [00:00<00:00,  6.28trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 79/79 [00:00<00:00,  3.91trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 80/80 [00:00<00:00, 17.16trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 81/81 [00:00<00:00,  3.23trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 82/82 [00:00<00:00,  4.25trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 83/83 [00:00<00:00, 21.85trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 84/84 [00:00<00:00, 11.66trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 85/85 [00:00<00:00,  2.57trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 86/86 [00:00<00:00, 12.24trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 87/87 [00:00<00:00,  5.38trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 88/88 [00:00<00:00, 29.32trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 89/89 [00:00<00:00, 21.67trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 90/90 [00:00<00:00,  6.55trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 91/91 [00:00<00:00, 13.27trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 92/92 [00:01<00:00,  1.31s/trial, best loss: 0.9977569924934134]\n",
      "100%|██████████| 93/93 [00:00<00:00,  1.03trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 94/94 [00:00<00:00,  1.89trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 95/95 [00:00<00:00,  9.75trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 96/96 [00:00<00:00,  3.20trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 97/97 [00:00<00:00,  3.94trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 98/98 [00:00<00:00,  3.94trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 99/99 [00:00<00:00,  1.98trial/s, best loss: 0.9977569924934134]\n",
      "100%|██████████| 100/100 [00:00<00:00,  7.27trial/s, best loss: 0.9977569924934134]\n",
      "-0.005490063841474546\n",
      "{'learner': RandomForestRegressor(max_depth=3, max_features=0.891101001609195, n_jobs=1,\n",
      "                      random_state=2, verbose=False), 'preprocs': (Normalizer(),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "estim = HyperoptEstimator(regressor= random_forest_regression('my_rf_reg'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "estim.fit(X_train, Y_train)\n",
    "\n",
    "print(estim.score(X_test, Y_test))\n",
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/trial, best loss: 1.032081307616948]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.90trial/s, best loss: 1.0220767479183208]\n",
      "100%|██████████| 3/3 [00:00<00:00,  6.60trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.45trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 5/5 [00:00<00:00,  1.30trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 6/6 [00:00<00:00,  1.67trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 7/7 [00:00<00:00,  6.81trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.03s/trial, best loss: 1.0042702282976341]\n",
      "100%|██████████| 9/9 [00:00<00:00, 13.76trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 10/10 [00:00<00:00,  1.01trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 11/11 [00:00<00:00,  8.55trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.10s/trial, best loss: 1.0042702282976341]\n",
      "100%|██████████| 13/13 [00:00<00:00,  2.10trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 14/14 [00:00<00:00,  1.01trial/s, best loss: 1.0042702282976341]\n",
      "100%|██████████| 15/15 [00:00<00:00, 15.34trial/s, best loss: 1.0033648677021765]\n",
      "100%|██████████| 16/16 [00:00<00:00, 22.49trial/s, best loss: 1.0033648677021765]\n",
      "100%|██████████| 17/17 [00:00<00:00,  7.10trial/s, best loss: 1.0033648677021765]\n",
      "100%|██████████| 18/18 [00:00<00:00, 10.11trial/s, best loss: 1.0033648677021765]\n",
      "100%|██████████| 19/19 [00:00<00:00, 20.76trial/s, best loss: 1.002501120201053]\n",
      "100%|██████████| 20/20 [00:01<00:00,  1.21s/trial, best loss: 1.0005925659973773]\n",
      "100%|██████████| 21/21 [00:00<00:00,  3.62trial/s, best loss: 0.998678944522464]\n",
      "100%|██████████| 22/22 [00:00<00:00,  2.28trial/s, best loss: 0.998678944522464]\n",
      "100%|██████████| 23/23 [00:00<00:00,  2.48trial/s, best loss: 0.998678944522464]\n",
      "100%|██████████| 24/24 [00:00<00:00,  2.88trial/s, best loss: 0.998678944522464]\n",
      "100%|██████████| 25/25 [00:00<00:00,  5.16trial/s, best loss: 0.9967508664162522]\n",
      "100%|██████████| 26/26 [00:00<00:00,  5.28trial/s, best loss: 0.9967508664162522]\n",
      "100%|██████████| 27/27 [00:00<00:00,  5.98trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 28/28 [00:00<00:00,  6.18trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 29/29 [00:00<00:00,  6.75trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 30/30 [00:00<00:00,  9.85trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 31/31 [00:00<00:00, 24.86trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 32/32 [00:00<00:00,  2.17trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 33/33 [00:00<00:00, 18.54trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 34/34 [00:00<00:00,  6.22trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 35/35 [00:00<00:00, 10.15trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 36/36 [00:01<00:00,  1.06s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 37/37 [00:00<00:00,  4.80trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 38/38 [00:00<00:00,  4.48trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 39/39 [00:00<00:00, 21.10trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 40/40 [00:00<00:00,  2.06trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 41/41 [00:00<00:00, 10.59trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 42/42 [00:01<00:00,  1.14s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 43/43 [00:00<00:00, 15.93trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 44/44 [00:00<00:00,  2.28trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 45/45 [00:00<00:00,  1.29trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 46/46 [00:00<00:00, 12.04trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 47/47 [00:00<00:00,  6.99trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 48/48 [00:00<00:00, 10.71trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 49/49 [00:00<00:00,  4.95trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 50/50 [00:00<00:00,  1.81trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 51/51 [00:00<00:00,  3.33trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 52/52 [00:00<00:00, 15.36trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 53/53 [00:00<00:00,  8.80trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 54/54 [00:00<00:00, 24.69trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 55/55 [00:00<00:00,  1.44trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 56/56 [00:00<00:00,  4.19trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 57/57 [00:02<00:00,  2.74s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 58/58 [00:00<00:00, 22.46trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 59/59 [00:00<00:00,  1.24trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 60/60 [00:02<00:00,  2.23s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 61/61 [00:00<00:00,  1.65trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 62/62 [00:00<00:00,  7.36trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 63/63 [00:02<00:00,  2.38s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 64/64 [00:00<00:00,  4.64trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 65/65 [00:00<00:00,  5.00trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 66/66 [00:00<00:00,  4.83trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 67/67 [00:00<00:00,  3.39trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 68/68 [00:00<00:00,  1.97trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 69/69 [00:00<00:00,  4.57trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 70/70 [00:00<00:00,  3.00trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 71/71 [00:00<00:00, 10.61trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 72/72 [00:00<00:00,  7.17trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 73/73 [00:00<00:00,  5.77trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 74/74 [00:00<00:00,  3.56trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 75/75 [00:00<00:00,  2.34trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 76/76 [00:00<00:00,  9.82trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 77/77 [00:00<00:00,  6.02trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 78/78 [00:00<00:00,  7.96trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 79/79 [00:00<00:00,  2.12trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 80/80 [00:00<00:00, 14.43trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 81/81 [00:00<00:00,  2.33trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 82/82 [00:00<00:00, 10.51trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 83/83 [00:00<00:00,  7.56trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 84/84 [00:00<00:00, 17.59trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 85/85 [00:00<00:00, 13.24trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 86/86 [00:00<00:00,  3.61trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 87/87 [00:00<00:00,  9.91trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 88/88 [00:00<00:00,  3.53trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 89/89 [00:00<00:00,  8.57trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 90/90 [00:00<00:00,  8.54trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 91/91 [00:00<00:00,  3.86trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 92/92 [00:01<00:00,  1.46s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 93/93 [00:00<00:00,  5.91trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 94/94 [00:00<00:00,  3.57trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 95/95 [00:00<00:00,  2.74trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 96/96 [00:00<00:00, 18.05trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 97/97 [00:00<00:00,  5.67trial/s, best loss: 0.9961094678385144]\n",
      "100%|██████████| 98/98 [00:01<00:00,  1.91s/trial, best loss: 0.9961094678385144]\n",
      "100%|██████████| 99/99 [00:00<00:00,  8.44trial/s, best loss: 0.9958682465628795]\n",
      "100%|██████████| 100/100 [00:00<00:00,  7.06trial/s, best loss: 0.9958682465628795]\n",
      "Estimated score: -0.004382587793090531\n",
      "Estimated best model: {'learner': RandomForestRegressor(max_depth=3, max_features='log2', n_estimators=94,\n",
      "                      n_jobs=1, random_state=4, verbose=False), 'preprocs': (PCA(n_components=12),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "estim = HyperoptEstimator(regressor= random_forest_regression('my_rf_reg'),\n",
    "                          preprocessing= [pca('my_pre')],\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=50,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "estim.fit(X_train, Y_train)\n",
    "\n",
    "print(f'Estimated score: {estim.score(X_test, Y_test)}')\n",
    "print(f'Estimated best model: {estim.best_model()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt with sklearn.MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bjkomer/hyperopt-tutorial/blob/master/MNIST-Example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_no_of_images = 50\n",
    "training_images_dir = \"data/train_shrinked/\"\n",
    "training_fnames = os.listdir(training_images_dir)\n",
    "\n",
    "pixel_array_list = []\n",
    "\n",
    "lens = []\n",
    "for fname in training_fnames:\n",
    "    im = Image.open(f'{training_images_dir}{fname}')\n",
    "    length = np.array(list(im.getdata())).shape[0]\n",
    "    lens.append(length)\n",
    "\n",
    "min_len = np.min(lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in training_fnames:\n",
    "    im = Image.open(f'{training_images_dir}{fname}')\n",
    "    \n",
    "    pix = im.load()\n",
    "    im_array = np.array(list(im.getdata()))\n",
    "    im_array_gray = np.mean(im_array, axis = 1)[:(min_len - 1)] # cut to minimum\n",
    "    pixel_array_list.append(im_array_gray)\n",
    "\n",
    "#pixels_df = pd.concat(pixel_array_list, axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 5247)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(pixel_array_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "train_df = pd.read_csv(f'{data_dir}/train.csv')\n",
    "#val_df = pd.read_csv(f'{data_dir}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(pixel_array_list) / 255.\n",
    "matches = [np.where(x == train_df.Id.values)[0][0] for x in [y[:len(y)-4] for y in os.listdir(\"data/train_shrinked/\")]]\n",
    "y = train_df.iloc[matches,:].Pawpularity.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:03<01:14,  3.90s/trial, best loss: -0.029876373626373628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:06<01:02,  3.45s/trial, best loss: -0.029876373626373628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:07<00:49,  2.91s/trial, best loss: -0.03159340659340659] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:09<00:40,  2.56s/trial, best loss: -0.03159340659340659]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:11<00:33,  2.26s/trial, best loss: -0.03365384615384615]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:14<00:35,  2.51s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:17<00:36,  2.78s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:21<00:35,  2.94s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:23<00:31,  2.86s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:28<00:33,  3.31s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:30<00:27,  3.02s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:32<00:21,  2.74s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [00:35<00:19,  2.74s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [00:38<00:16,  2.80s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [00:39<00:12,  2.47s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [00:42<00:09,  2.48s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [00:45<00:07,  2.59s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [00:48<00:05,  2.82s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [00:50<00:02,  2.53s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:52<00:00,  2.64s/trial, best loss: -0.034340659340659344]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.033000\n",
      "Testing Accuracy: 0.034341\n",
      "{'activation': 0, 'algorithm': 1, 'alpha': 0.0001336183842118413, 'layer_size': 93.0, 'learning_rate': 0.6029980867483039}\n",
      "{'state': 2, 'tid': 5, 'spec': None, 'result': {'loss': -0.034340659340659344, 'status': 'ok', 'model': MLPClassifier(activation='logistic', alpha=0.0001336183842118413,\n",
      "              hidden_layer_sizes=(93,), learning_rate_init=0.6029980867483039,\n",
      "              max_iter=10, random_state=1, solver='sgd')}, 'misc': {'tid': 5, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [5], 'algorithm': [5], 'alpha': [5], 'layer_size': [5], 'learning_rate': [5]}, 'vals': {'activation': [0], 'algorithm': [1], 'alpha': [0.0001336183842118413], 'layer_size': [93.0], 'learning_rate': [0.6029980867483039]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2021, 12, 29, 19, 10, 12, 14000), 'refresh_time': datetime.datetime(2021, 12, 29, 19, 10, 15, 84000)}\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test = X[:7000], X[7000:]\n",
    "y_train, y_test = y[:7000], y[7000:]\n",
    "\n",
    "# Define an objective function to minimize\n",
    "# The classifier will be created, trained, and scored within this function\n",
    "def objective(args):\n",
    "    \n",
    "    # Build a classifier based on the parameters chosen\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(int(args['layer_size']),), max_iter=10,\n",
    "                        alpha=args['alpha'], solver=args['algorithm'], tol=1e-4, \n",
    "                        random_state=1, activation=args['activation'], \n",
    "                        learning_rate_init=args['learning_rate']\n",
    "                       )\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    #NOTE: Normally you should use a separate 'validation' set here\n",
    "    #      and have a 'test' set that is only used on the final classifier\n",
    "    #      once parameters have been selected, the final classifier can be\n",
    "    #      retrained on both the 'training' and 'validation' sets\n",
    "    loss = -mlp.score(X_test, y_test)\n",
    "    \n",
    "    # Must return loss and status, any additional information can also be saved here.\n",
    "    # In this example the fully trained model is also returned\n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model':mlp}\n",
    "\n",
    "# Define the parameter space to search over\n",
    "# In this case the objective function is expecting a single dictionary argument, \n",
    "# so the space variable is set up to match that\n",
    "space = {'layer_size':hp.quniform('layer_size', 25, 100, 1),\n",
    "         'alpha':hp.lognormal('alpha', mu=np.log(1e-4), sigma=1),\n",
    "         'algorithm':hp.choice('algorithm', ['lbfgs', 'sgd', 'adam']),\n",
    "         'activation':hp.choice('activation', ['logistic', 'tanh', 'relu']),\n",
    "         #'learning_rate':hp.uniform('learning_rate', low=0.001, high=0.999),\n",
    "         'learning_rate':hp.loguniform('learning_rate', low=np.log(1e-4), high=np.log(1.)),\n",
    "        }\n",
    "\n",
    "# Create a Trials object to store results of each evaluation\n",
    "trials = Trials()\n",
    "\n",
    "# Run the search for the specified number of evaluations\n",
    "best = fmin(objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=20)\n",
    "\n",
    "# Get the trained model from the best trial\n",
    "best_model = trials.best_trial['result']['model']\n",
    "\n",
    "# Compute the training and testing scores on this model\n",
    "print(\"Training Accuracy: %f\" % best_model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy: %f\" % best_model.score(X_test, y_test))\n",
    "\n",
    "print(best)\n",
    "print(trials.best_trial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:50,  5.61s/trial, best loss: -0.9524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:08<00:38,  4.84s/trial, best loss: -0.9524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:15<00:37,  5.34s/trial, best loss: -0.9524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:21<00:33,  5.59s/trial, best loss: -0.9524]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:29<00:31,  6.33s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:38<00:28,  7.19s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:44<00:20,  6.75s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:50<00:13,  6.64s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:57<00:06,  6.69s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:04<00:00,  6.43s/trial, best loss: -0.9703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/revilo/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Accuracy: 0.981250\n",
      "Testing Accuracy: 0.970300\n",
      "{'activation': 2, 'algorithm': 1, 'alpha': 0.0002032864657772866, 'layer_size': 84.0, 'learning_rate': 0.024929603536400023}\n",
      "{'state': 2, 'tid': 4, 'spec': None, 'result': {'loss': -0.9703, 'status': 'ok', 'model': MLPClassifier(alpha=0.0002032864657772866, hidden_layer_sizes=(84,),\n",
      "              learning_rate_init=0.024929603536400023, max_iter=10,\n",
      "              random_state=1, solver='sgd')}, 'misc': {'tid': 4, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [4], 'algorithm': [4], 'alpha': [4], 'layer_size': [4], 'learning_rate': [4]}, 'vals': {'activation': [2], 'algorithm': [1], 'alpha': [0.0002032864657772866], 'layer_size': [84.0], 'learning_rate': [0.024929603536400023]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2021, 12, 29, 17, 55, 41, 835000), 'refresh_time': datetime.datetime(2021, 12, 29, 17, 55, 49, 866000)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "#mnist = fetch_mldata('MNIST original')\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "# Scale the images to be between 0 and 1\n",
    "X = mnist.data / 255.\n",
    "y = mnist.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "# Define an objective function to minimize\n",
    "# The classifier will be created, trained, and scored within this function\n",
    "def objective(args):\n",
    "    \n",
    "    # Build a classifier based on the parameters chosen\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(int(args['layer_size']),), max_iter=10,\n",
    "                        alpha=args['alpha'], solver=args['algorithm'], tol=1e-4, \n",
    "                        random_state=1, activation=args['activation'], \n",
    "                        learning_rate_init=args['learning_rate']\n",
    "                       )\n",
    "    \n",
    "    # Fit the classifier to the training data\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    #NOTE: Normally you should use a separate 'validation' set here\n",
    "    #      and have a 'test' set that is only used on the final classifier\n",
    "    #      once parameters have been selected, the final classifier can be\n",
    "    #      retrained on both the 'training' and 'validation' sets\n",
    "    loss = -mlp.score(X_test, y_test)\n",
    "    \n",
    "    # Must return loss and status, any additional information can also be saved here.\n",
    "    # In this example the fully trained model is also returned\n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model':mlp}\n",
    "\n",
    "# Define the parameter space to search over\n",
    "# In this case the objective function is expecting a single dictionary argument, \n",
    "# so the space variable is set up to match that\n",
    "space = {'layer_size':hp.quniform('layer_size', 25, 100, 1),\n",
    "         'alpha':hp.lognormal('alpha', mu=np.log(1e-4), sigma=1),\n",
    "         'algorithm':hp.choice('algorithm', ['lbfgs', 'sgd', 'adam']),\n",
    "         'activation':hp.choice('activation', ['logistic', 'tanh', 'relu']),\n",
    "         #'learning_rate':hp.uniform('learning_rate', low=0.001, high=0.999),\n",
    "         'learning_rate':hp.loguniform('learning_rate', low=np.log(1e-4), high=np.log(1.)),\n",
    "        }\n",
    "\n",
    "# Create a Trials object to store results of each evaluation\n",
    "trials = Trials()\n",
    "\n",
    "# Run the search for the specified number of evaluations\n",
    "best = fmin(objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=10)\n",
    "\n",
    "# Get the trained model from the best trial\n",
    "best_model = trials.best_trial['result']['model']\n",
    "\n",
    "# Compute the training and testing scores on this model\n",
    "print(\"Training Accuracy: %f\" % best_model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy: %f\" % best_model.score(X_test, y_test))\n",
    "\n",
    "print(best)\n",
    "print(trials.best_trial)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.9524,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.0005181376624604576,\n",
       "                hidden_layer_sizes=(39,), learning_rate_init=0.04838476009377832,\n",
       "                max_iter=10, random_state=1, solver='sgd')},\n",
       " {'loss': -0.8715,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=3.6647592130329364e-05, hidden_layer_sizes=(70,),\n",
       "                learning_rate_init=0.01895107026278117, max_iter=10,\n",
       "                random_state=1, solver='lbfgs')},\n",
       " {'loss': -0.9245,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='tanh', alpha=0.00012916337960198752,\n",
       "                hidden_layer_sizes=(46,),\n",
       "                learning_rate_init=0.0027405589150218323, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.0894,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=0.0002968708755733914, hidden_layer_sizes=(40,),\n",
       "                learning_rate_init=0.5928035423594112, max_iter=10,\n",
       "                random_state=1)},\n",
       " {'loss': -0.9703,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=0.0002032864657772866, hidden_layer_sizes=(84,),\n",
       "                learning_rate_init=0.024929603536400023, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.9692,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=2.2550565511431326e-05,\n",
       "                hidden_layer_sizes=(93,), learning_rate_init=0.025533803787111762,\n",
       "                max_iter=10, random_state=1)},\n",
       " {'loss': -0.9685,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=7.917304400527648e-05, hidden_layer_sizes=(39,),\n",
       "                learning_rate_init=0.2208879491050894, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.8941,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(alpha=0.0003198301644391391, hidden_layer_sizes=(71,),\n",
       "                learning_rate_init=0.0003904881155054144, max_iter=10,\n",
       "                random_state=1, solver='sgd')},\n",
       " {'loss': -0.5596,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=3.735815757090899e-05,\n",
       "                hidden_layer_sizes=(61,), learning_rate_init=0.000174419977854624,\n",
       "                max_iter=10, random_state=1, solver='sgd')},\n",
       " {'loss': -0.6206,\n",
       "  'status': 'ok',\n",
       "  'model': MLPClassifier(activation='logistic', alpha=0.00013585336654081093,\n",
       "                hidden_layer_sizes=(36,),\n",
       "                learning_rate_init=0.0003093851506720561, max_iter=10,\n",
       "                random_state=1, solver='sgd')}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
